---
title: '**NeuroKit2: A Python Toolbox for Neurophysiological Signal Processing**'
shorttitle        : "NeuroKit2"
author:
  - name          : "Dominique Makowski"
    affiliation   : " 1,*"
    corresponding : no    # Define only one corresponding author
    address       : "HSS 04-18, 48 Nanyang Avenue, Singapore"
    email         : "dmakowski@ntu.edu.sg"
  - name          : "Tam Pham"
    affiliation   : " 1"
  - name          : "Zen J. Lau"
    affiliation   : " 1"
  - name          : "Jan C. Brammer"
    affiliation   : " 2"
  - name          : "Hung Pham"
    affiliation   : " 3"
  - name          : "Francois Lespinasse"
    affiliation   : " 4"
  - name          : "Christopher Sch\\\"{o}lzel"
    affiliation   : " 5"
  - name          : "S.H. Annabel Chen"
    affiliation   : " 1, 6, 7"
affiliation:
  - id            : "1"
    institution   : "School of Social Sciences, Nanyang Technological University, Singapore"
  - id            : "2"
    institution   : "???"
  - id            : "3"
    institution   : "???"
  - id            : "4"
    institution   : "Departement de psychologie, Universite de Montreal, Montreal, Canada"
  - id            : "5"
    institution   : "Life Science Informatics, THM University of Applied Sciences, Gisslen, Germany"
  - id            : "6"
    institution   : "Centre for Research and Development in Learning, Nanyang Technological University, Singapore"
  - id            : "7"
    institution   : "Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore"
authornote: |
  * Correspondence concerning this article should be addressed to Dominique Makowski (HSS 04-18, 48 Nanyang Avenue, Singapore; dmakowski@ntu.edu.sg).
abstract: |
   NeuroKit2 is an open-source, user-friendly Python package dedicated to neurophysiological signal processing. Its design philosophy, which is centred on user-experience and a collaborative environment, offers programming ease for both novice and advanced users to implement processing and analyses pipelines for a suite of different signal types (e.g., electrocardiogram (ECG), respiratory (RSP), electrodermal activity (EDA), and electromyography (EMG)).  While efficiency is maximized with high-level functions that combines the processing or analysis of multiple signals using sensible defaults, lower level functions confer flexibiity and parametric control, allowing more advanced users to build their own custom analysis pipeline. With the current lack of open-source tools needed for comprehensive signal processing, Neurokit2 presents new opportunities for researchers to move away from unreadable black-box algorithms and towards greater control over their results, improving transparency and reproducibility in research. The open-science nature of NeuroKit presents a viable platform for researchers and experts of related fields to contribute to its continual developments, allowing NeuroKit to remain reliable and cutting-edge.  
keywords          : "Neurophysiology, Biosignals, Python, ECG, EDA, EMG, RSP"
wordcount         : ""
bibliography      : ["bibliography.bib"]
floatsintext      : yes
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output:
  papaja::apa6_pdf:
    keep_tex: FALSE
    latex_engine: xelatex
  papaja::apa6_word:
    keep_tex: FALSE
header-includes:
   - \usepackage[labelfont=bf, font={color=gray,small}]{caption}
   - \usepackage{float}
   - \usepackage[document]{ragged2e}
editor_options:
  chunk_output_type: console
---

\justify

```{r r_setup, include = FALSE, warning=FALSE, message=FALSE}
library("papaja")
library("kableExtra")
options(knitr.kable.NA = 'None')

library(tidyverse)
library(easystats)

# Setup python - you need to change the path to your python distribution
library(reticulate)
reticulate::use_python("D:/Downloads/WPy64-3810/python-3.8.1.amd64/")
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
```



<!-- Research gap -->
Cognitive neuroscience and psychology are increasingly relying on neurophysiological methods to assess brain and bodily activity. These approaches include electroencephalography (EEG), electrocardiography (ECG), electromyography (EMG) and electrodermal activity (EDA) signals. This trend was driven not only by theoretical motivations [e.g., the growth of embodied or affective neuroscience; @Kiverstein2015], but also by practical reasons including low monetary cost (especially compared with other imaging techniques, such as MRI or MEG), high user convenience (e.g., portability, setup speed), and the increasing availability of recording devices [e.g., in smart watches; @yuehong2016internet]. Together with the development of recording tools, advancements in the fields of signal processing and computational data science bolstered the emergence of new processing algorithms [@clifton2012machine; @roy2019deep], in turn offering a myriad of novel methods for users to process and analyze neurophysiological signals. 

Unfortunately, because most of the algorithms are implemented as code, neurophysiological data processing remains a challenge for many researchers without a formal training or experience in programming. Moreover, many existing implementations are also limited to one type of signals (for instance, focused on ECG or EDA), which makes it inconvenient for researchers who might have to learn and concurrently rely on different software to process multimodal data.

<!-- Response to gap -->
*NeuroKit2* aims at addressing these challenges by offering a free, user-friendly, and comprehensive solution for neurophysiological data processing. It is an open-source Python package, developed in a collaborative environment that continues to welcome contributors from different countries and fields. Historically, *NeuroKit2* is the re-forged successor *NeuroKit1* (*https://github.com/neuropsychology/NeuroKit.py*), a PhD side project that ended up benefiting an important community of users (252 GitHub stars as of 03-05-2020). The new version takes on its best features and design choices, and re-implements them in a professional and well-thought way. It aims at being 1) accessible and well-documented, 2) reliable and cutting-edge, and 3) flexible and efficient.

<!-- Accessibility and documentation -->
Being available for Python 3 [@python3], one of the most popular programming languages, *NeuroKit2's* users benefit from an important amount of existing tutorials and a large online community. The package is also relatively lightweight, using mainly standard dependencies [@scipy] such as *NumPy*, *pandas*, *SciPy*, *scikit-learn* and *MatplotLib* (with an additional system of optional dependencies), enabling its use as a dependency in other software. The package source code is available under a permissive license on GitHub (*https://github.com/neuropsychology/NeuroKit*). Its documentation, automatically built and rendered from the code [@sphinx-tobe-added], is hosted at *https://neurokit2.readthedocs.io/*. Apart from guides for installation and contribution, and a description of the package's functions, the documentation also includes several "hands-on" examples and tutorials providing a walk-through on how to address specific issues (e.g., how to extract and visualize individual heartbeats, how to analyze event-related data). New examples can be easily added by users simply by uploading a Python notebook file [@kluyver2016jupyter] to the repository. This file will be automatically transformed into a webpage and displayed on the website, ensuring a transparent and evolutive documentation. Moreover, these examples can be used interactively via a cloud-based *Binder* environment [@Jupyter2018], allowing users to try out the features directly in their browser. Finally, the accessibility for newcomers is reinforced by the issue tracker of GitHub, where users can create public issues to inquire for help.

<!-- Reliability and Evolution -->
The package aims at being reliable and trustworthy, including peer-reviewed processing pipelines and functions tested against existing implementations of established reference software such as *BioSPPy* [@biosppy], *hrv* [*under review*](https://github.com/openjournals/joss-reviews/issues/1867), *PySiology* [@PySiology], *HeartPy* [@HeartPy], *systole* [@Systole] or *nolds* [@nolds]. The code itself includes a comprehensive test suite using continuous integration tools [e.g., @travis-tobe-added] to ensure stability and prevent errors. Moreover, users are able to easily report any bugs and be notified of their fixes via the issue tracker. Thanks to its collaborative and open development as well as its modular organization, *NeuroKit2* can easily follow the latest developments and remain cutting-edge through its ability to evolve, adapt, and integrate new methods as they are emerging.


<!-- Powerful and flexible: API -->
Finally, we believe that the design philosophy of *NeuroKit2* contributes to an efficient (i.e., allowing to achieve a lot with few functions)  yet flexible (i.e., enabling fine control and precision over what is done) user interface (API). We will illustrate these claims with two examples of common use-cases (the analysis of event-related and resting state data), and will conclude by discussing how *NeuroKit2* contributes to neurophysiological research by raising the standards for validity, reproducibility and accessibility.


# Design Philosophy

As stated above, *NeuroKit2* aims at being accessible to beginners and, at the same time, offering a maximal level of control to experienced users. This is achieved by allowing beginning users to implement complex processing and analyses pipelines with very few functions, while still enabling fine-tuned control and precision to more experienced users. In concrete terms, this trade-off is allowed by the implementation of three abstract levels of functions.


## Low-level: Base Utilities for Signal Processing

The basic building blocks are functions to facilitate general signal processing, i.e., to do filtering, resampling, interpolating, peak detection, etc. These functions are signal-agnostic, and include a lot of tweakable parameters. For instance, one can change the filtering method, frequencies, order and such. Most of these functions are based on validated algorithms present in *scipy* [@scipy]. Examples of such functions include `signal_filter()`, `signal_interpolate()`, `signal_resample()`, `signal_detrend()`, and `signal_findpeaks()`.


## Mid-level: Neurophysiological Processing Steps

The signal processing utilities are then used by functions specific to the different types of physiological signals (i.e., ECG, RSP, EDA, EMG, PPG). These functions aim at taking care of specific steps of physiological data processing, such as cleaning, peak detection, phase classification or rate computation. Critically, for each type of signals, the same function names are called (in the form `signaltype_functiongoal()`) to achieve equivalent goals, e.g., `*_clean()`, `*_findpeaks()`, `*_process()`, `*_plot()`, making it intuitive and consistent across different modalities.

For example, the `rsp_clean()` function uses `signal_filter()` and `signal_detrend()`, with different possible sets of default parameters that can be switched via a "method" argument (corresponding to different published or validated pipelines). For instance, setting `method="khodadad2018"` will use the cleaning workflow described in @khodadad2018optimized. However, if a user wants to build its own custom cleaning pipeline, she or he can use the cleaning function as a template, and directly tweak the parameters in the low-level signal processing operations.


## High-level Wrappers for Processing and Analysis

These steps are then assembled in "master" functions, that are usually the entry point for new users. For instance, the `ecg_process()` function uses `ecg_clean()`, `ecg_findpeaks()`, `ecg_rate()`. A general processing pipeline can be selected via the `method` argument, that is then propagated throughout its lower-level functions. Easily switching between processing pipelines allows for the comparison of different methods, and streamlines critical but time-consuming steps in reproducible research, such as the validation of data preparation and quality control [@Quintana2016]. Finally, the package includes convenience meta-functions (e.g., `bio_process`) that enable the combined processing of multiple types of signals at once (e.g., `bio_process(ecg=ecg_signal, eda=eda_signal)`).

Performing a set of operations with sensible default parameters can be rewarding, especially for beginners, allowing them to perform cutting-edge processing or replication of research steps without requiring a programming expertise. Moreover, it contributes to the demystification of the usage of "pure" programming tools (as opposed to GUI-based software such as *SPSS*, *Kubios*, or *Acqknowledge*), providing a welcoming framework to further understand the frontend, backend and the in-betweens of physiological data processing. Importantly, more advanced users can again very easily build their own custom analysis pipeline by using the mid-level functions, allowing for a finer control over the processing parameters.

Overall, we believe that this code structure offers a calibrated trade-off between flexibility and user-friendliness, with functions that are easy to memorize and implement. We hope that it may further encourage researchers to become part of a supportive open-science community construed of many expertises - rather than relying on closed and proprietary software - to achieve their goals.


# Example

In this section, we present two examples that illustrate the most common use-cases. The first example is an event-related paradigm, in which the interest lies in the momentarily short-term physiological changes related to specific stimuli, whereas the second shows how to extract the characteristics (features) of physiological activity during a longer period of time (not necessarily tied to a specific and sudden event). The example datasets are made available with the package and can be downloaded using the `data()` function.


## Event-related Paradigm

This example dataset contains ECG, RSP and EDA signals of one participant to whom were presented four emotional images [from the NAPS database; @marchewka2014nencki], in a typical (albeit highly shortened) experimental psychology paradigm.

Signals are 2.5 minutes long and are recorded at a frequency of 100Hz [note that the sampling rate is low for storage purposes and should be higher in actual recordings, see @Quintana2016]. It has 4 channels including three physiological signals, and one corresponding to the marking of events via a photosensor (which signal decreased when a stimulus appeared on the screen).


```{python eventrelated_data, include=TRUE, eval=TRUE, echo = TRUE}
# Load the package
import neurokit2 as nk

# Download the example dataset
data = nk.data("bio_eventrelated_100hz")

# Visualize 10 seconds of data (on the same scale)
nk.signal_plot(data[900:1900], standardize=True)
```

```{r include=TRUE, eval=TRUE, echo = FALSE, fig.width=10, fig.height=6, fig.cap="Subset of the dataset showing one event (in orange) and the other physiological signals."}
py$data %>%
  standardize() %>%
  mutate(Time = 1:n() / 100) %>%
  slice(900:1900) %>%
  pivot_longer(1:4) %>%
  mutate(name = fct_relevel(name, c("ECG", "RSP", "EDA", "Photosensor"))) %>%
  ggplot(aes(x=Time, y=value, color=name, size=name)) +
  geom_line() +
  theme_modern() +
  scale_color_manual(values=c("ECG"="red", "EDA"="#9C27B0", "RSP"="#2196F3", "Photosensor"="#FF9800")) +
  scale_size_manual(values=c("ECG"=0.66, "EDA"=2, "RSP"=2, "Photosensor"=2)) +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        legend.title = element_blank(),
        legend.position = "top") +
  ylab("Time (s)") +
  guides(size = guide_legend(override.aes = list(size = 2)))
```

```{python epochs_creation, include=TRUE, results="hide", eval=TRUE, echo = TRUE}
# Process the data
df, info = nk.bio_process(ecg=data["ECG"],
                          rsp=data["RSP"],
                          eda=data["EDA"],
                          sampling_rate=100)

# Find events
conditions = ["Negative", "Neutral", "Neutral", "Negative"]
events = nk.events_find(event_channel=data["Photosensor"],
                        threshold_keep='below',
                        event_conditions=conditions)

# Epoch the data
epochs = nk.epochs_create(data=df,
                          events=events,
                          sampling_rate=100,
                          epochs_start=-0.1,
                          epochs_end=4)
```

```{python eventrelated_analysis, include=TRUE, results="hide", eval=TRUE, echo = TRUE}
# Extract event related features
results = nk.bio_analyze(epochs)

# Show subset of results
results[["Condition", "ECG_Rate_Mean", "RSP_Rate_Mean", "EDA_Peak_Amplitude"]]
```

```{r table1word, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# For word
knitr::kable(py$results[c("Condition", "ECG_Rate_Mean", "RSP_Rate_Mean", "EDA_Peak_Amplitude")], format="markdown", digits = 3, caption = "Subset of the ouput related to event-related analysis characterizing the pattern of physiological changes related to specific stimuli.", row.names = FALSE)
```
```{r table1pdf, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, out.width = "\\textwidth", fig.pos = "!ht", results = "asis"}
# For PDFs
kable(py$results[c("Condition", "ECG_Rate_Mean", "RSP_Rate_Mean", "EDA_Peak_Amplitude")], format="latex", digits = 2, booktabs = TRUE, caption = "Subset of the ouput related to event-related analysis characterizing the pattern of physiological changes related to specific stimuli.", linesep="") %>%
  kableExtra::kable_styling(latex_options = c("hold_position"))
```


In this example, after loading the package and the example dataset, each physiological signal is processed using `bio_process()`. Data from the photosensor is processed separately with `events_find()`, that locates the stimuli onsets in the signal. Once we have preprocessed signals and the location of events, we can slice the data into segments corresponding to a time window (ranging from -0.1 to 4 seconds) around each stimulus with `epochs_create()`. Finally, relevant features are computed for each epoch (i.e., each stimulus) by providing them to `bio_analyze()`.

The features include for example the changes in rates of ECG and RSP signals (e.g. maximum, minimum and mean rate after stimulus onset, and the time at which they occur), and the peak characteristics of EDA signal (e.g., occurrence of skin conductance response (SCR), and if SCR is present, its corresponding peak amplitude, time of peak, rise and recovery time). In addition, respiration and cardiac cycle phases are also extracted (i.e., the respiration phase - inspiration/expiration - and cardiac phase - systole/diastole - occurring at the onset of event).

This example shows the straightforward process of extracting features of physiological responses. This pipeline can easily scale up to group-level analysis by aggregating the average of features across subjects. In addition to streamlining data analyses, *NeuroKit2* aims to provide researchers an extensive suite of signal features, allowing for precise interpretations in terms of relationship between physiological activity and neurocognitive processes. In this example (see **Table 1**), exposure to negative stimuli, as compared to neutral stimuli, is related to stronger cardiac deceleration, higher skin conductance response, and accelerated breathing rate (note that this illustrative interpretation is purely descriptive).



## Resting-state Features

The second dataset corresponds to 5 minutes physiological activity of a human participant at rest (eyes-closed in a seated position), under no specific set of instructions. It contains three channels (ECG, PPG and RSP) sampled at a frequency of 100Hz.

```{python intervalrelated, include=TRUE, results="hide", eval=TRUE, echo = TRUE}
# Load the package
import neurokit2 as nk

# Download the example dataset
data = nk.data("bio_resting_5min_100hz")

# Process the data
df, info = nk.bio_process(ecg=data["ECG"],
                          rsp=data["RSP"],
                          sampling_rate=100)

# Extract features
results = nk.bio_analyze(df)

# Show subset of results
results[["ECG_Rate_Mean", "ECG_HRV_RMSSD", "RSP_Rate_Mean", "RSA_P2T_Mean"]]
```

```{r table2word, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# For word
knitr::kable(py$results[c("ECG_Rate_Mean", "ECG_HRV_RMSSD", "RSP_Rate_Mean", "RSA_P2T_Mean")], format="markdown", digits = 3, caption = "Subset of properties characterizing the physiological activity over a period of 5 minutes of resting-state", row.names = FALSE)
```
```{r table2pdf, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, out.width = "\\textwidth", fig.pos = "!ht", results = "asis"}
# For PDFs
kable(py$results[c("ECG_Rate_Mean", "ECG_HRV_RMSSD", "RSP_Rate_Mean", "RSA_P2T_Mean")], format="latex", digits = 2, booktabs = TRUE, caption = "Subset of properties characterizing the physiological activity over a period of 5 minutes of resting-state.", linesep="") %>%
  kableExtra::kable_styling(latex_options = c("hold_position"))
```



In this example, the steps of the analysis are in fact identical to the previous example, including loading the package, the dataset and processing the data. The difference is that here there is no epoching, as we want to compute features related to the whole dataset. Thus, we can directly pass the dataframe to `bio_analyze()`, which will detect that these are not epochs, and compute the appropriate features accordingly. These include for instance the average heart and breathing rate, as well as indices of heart rate variability (HRV) and respiratory sinus arrhythmia (RSA).


This example illustrates a second type of physiological analysis, that we could refer to as interval-related (as opposed to event-related), where one is typically interested in computing features of signal variability and activation patterns over a longer-term period or interval of time (typically more than a few seconds, as is generally the case in event-related paradigms). The simplicity of usage of *NeuroKit2* allows for the fast creation of a standardized and reproducible pipeline to describe physiological activity.





# Discussion

*NeuroKit2* is a neurophysiological signal processing software accessible to people with very little knowledge of programming, attributed to its design choices focusing on user-experience and collaborative community. It is also a pragmatic answer to the broader need for transparent and reproducible methods in neurophysiology. Its modular organization not only facilitates the use of existing and validated processing pipelines, but is also an viable platform for experimentation and innovation.

We expect future evolution to be mostly driven by the community and the advances in related fields. Possible directions include extending the support for other types of bodily signals (e.g., electrogastrography - EGG, electrooculography - EOG) and strengthening the efficiency of the code to obtain performance gains for large datasets. Further validation of the available processing pipelines could be made through the (re)analysis of public databases. In line with this objective, the support of standardized data structure formats (e.g. WFDB, BIDS, ...) could be extended.

In conclusion, we think *NeuroKit2* provides useful tools not only for novice and senior researchers, but amateurs and tech-enthusiasts interested in health or embodied aspects of (neuro)psychology. Whether the data is produced by "smart health devices" or academic research-grade equipment, the package foster reproducible science. Critically, it is a community-oriented project. By increasing the autonomy of researchers and practitioners, and by shortening the delay between data collection and results acquisition, *NeuroKit2* could be useful beyond fundamental research in neuroscience and psychology, including applications such as biofeedback, personal physiological monitoring and sport research.


# Conflict of Interest

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

# Acknowledgements

We would like to thank Prof. C. F. Xavier for inspiration, all the contributors (https://neurokit2.readthedocs.io/en/latest/authors.html), and the users for their support.



\newpage

# References
```{r create_r-references}
r_refs(file = "bibliography.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
