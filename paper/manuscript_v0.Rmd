---
title: '**NeuroKit2: A Python Toolbox for Neurophysiological Signal Processing**'
shorttitle        : "NeuroKit2"
author:
  - name          : "Dominique Makowski"
    affiliation   : " 1,*"
    corresponding : no    # Define only one corresponding author
    address       : "HSS 04-18, 48 Nanyang Avenue, Singapore"
    email         : "dmakowski@ntu.edu.sg"
  - name          : "Tam Pham"
    affiliation   : " 1"
  - name          : "Zen J. Lau"
    affiliation   : " 1"
  - name          : "Jan C. Brammer"
    affiliation   : " 2"
  - name          : "Hung Pham"
    affiliation   : " 3"
  - name          : "Francois Lespinasse"
    affiliation   : " 4"
  - name          : "Christopher Sch\\\"{o}lzel"
    affiliation   : " 5"
  - name          : "S.H. Annabel Chen"
    affiliation   : " 1, 6, 7"
affiliation:
  - id            : "1"
    institution   : "School of Social Sciences, Nanyang Technological University, Singapore"
  - id            : "2"
    institution   : "???"
  - id            : "3"
    institution   : "???"
  - id            : "4"
    institution   : "Departement de psychologie, Universite de Montreal, Montreal, Canada"
  - id            : "5"
    institution   : "Life Science Informatics, THM University of Applied Sciences, Gisslen, Germany"
  - id            : "6"
    institution   : "Centre for Research and Development in Learning, Nanyang Technological University, Singapore"
  - id            : "7"
    institution   : "Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore"
authornote: |
  * Correspondence concerning this article should be addressed to Dominique Makowski (HSS 04-18, 48 Nanyang Avenue, Singapore; dmakowski@ntu.edu.sg).
abstract: |
   NeuroKit2 is an open-source user-friendly Python package dedicated to neurophysiological signal processing. It developed from a collaborative project aimed at offering programming ease for both novice and advanced users to perform elaborate analyses of electrocardiogram (ECG), respiratory (RSP), electrodermal activity (EDA), and electromyography (EMG) data. It comprises of a consistent set of user-friendly, high-level functions that implements an all-in-one cleaning, preprocessing, and processing pipeline with sensible defaults. At the same time, greater flexibility and parametric control can be achieved by using Neurokit2's mid-level functions to build a custom analysis pipeline. (talk about novelty? or cutting-edge measure extraction? or reproducibility?)
keywords          : "Neurophysiology, Biosignals, Python, ECG, EDA, EMG, RSP"
wordcount         : ""
bibliography      : ["bibliography.bib"]
floatsintext      : yes
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output:
  papaja::apa6_pdf:
    keep_tex: FALSE
    latex_engine: xelatex
  papaja::apa6_word:
    keep_tex: FALSE
header-includes:
   - \usepackage[labelfont=bf, font={color=gray,small}]{caption}
   - \usepackage{float}
   - \usepackage[document]{ragged2e}
editor_options:
  chunk_output_type: console
---

\justify

```{r r_setup, include = FALSE, warning=FALSE, message=FALSE}
library("papaja")
library("kableExtra")
options(knitr.kable.NA = 'None')

library(tidyverse)
library(easystats)

# Setup python - you need to change the path to your python distribution
library(reticulate)
reticulate::use_python("D:/Downloads/WPy64-3810/python-3.8.1.amd64/")
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
```




<!-- Research gap -->
As it becomes clearer that cognitive processes are reliant on whole living body activity, the fields of cognitive neuroscience and psychology are increasingly looking onto neurophysiological methods to investigate brain-body interactions [@Kiverstein2015]<!--felt like a ref was needed to support the claim that it is de facto increasing-->. Other reasons can include low monetary cost (especially compared with other imaging techniques, such as MRI), high user convenience (e.g., portability, setup speed) and wide availability (e.g., in "smart" devices) <!-- easier to attain ecological validity ?-->. At the same time, the fields of signal processing and computational data science continue to grow in complexity, allowing for benchmarked processing pipelines and valid/transparent implementations of complexity measures <!--pushing like never before the horizon of possibilities and opportunities -- what opportunities are talking about? providing examples would be great (e.g. valid and transparent implementations of complexity measures, or myriad of preprocessing and analysis pipelines have been developed)-->. However, as these methods are often not easily accessible and user-friendly, neurophysiological data processing remains a challenge for many researchers without a formal training or experience in programming.

<!-- Response to gap -->
*NeuroKit2* aims at addressing this gap by offering a free and user-friendly solution for neurophysiological data processing. It is an open-source Python package, developed in a collaborative environment that continues to welcome contributors from different countries and fields. Historically, *NeuroKit2* is the re-forged successor *NeuroKit.py* (*https://github.com/neuropsychology/NeuroKit.py*), a PhD side project that ended up attracting a lot of users and success (248 GitHub stars as of 09-04-2020). The new version takes on its best features and design choices, and re-implements them in a professional and well-thaught way. It aims at being 1) accessible, 2) well-documented, 2) reliable, 4) cutting-edge and 5) powerful.

<!-- Accessibility and documentation -->
The package is available for Python 3 [@python3] and thus benefits from its important base of users, existing tutorials and large online community. It is also relatively lightweight, using mainly standard dependencies [@scipy] such as *NumPy*, *pandas*, *SciPy*, *scikit-learn* and *MatplotLib* (with an additional system of optional dependencies), enabling its use as a dependency in other software. The package source code is available under a permissive license on GitHub (*https://github.com/neuropsychology/NeuroKit*); along with its documentation, automatically built and hosted at *https://neurokit2.readthedocs.io/*. Apart from instructions for installation and contribution, and a decription of the package's functions, the documentation also includes several cloud-based interactive examples, as well as tutorials providing a walk-through on how to address specific issues (for instance, how to extract and visualize individual heartbeats). New examples can be easily added by users simply by uploading a Python notebook file to the repository. This notebook will be automatically rendered in the documentation webpage, and also accessible to everyone who wishes to interact with its content (no prior installation needed) via a *Binder* environment [@Jupyter2018]. <!--(maybe referencing our binder would be a good idea at this point) This notebook file will be automatically transformed into a webpage and displayed on the website--> This ensures a transparent and evolutive documentation. The accessibility for newcomers is also reinforced by the issue tracker of GitHub, where users can create public issues to inquire for help.

<!-- Reliability and Evolution -->
The package aims at being reliable and trustworthy, that is implementations of peer-reviewed processing techniques and pipelines. Its functions are also tested against existing implementations of established reference software such as *BioSPPy* [@biosppy], *hrv* [*under review*](https://github.com/openjournals/joss-reviews/issues/1867), *PySiology* [@PySiology], *HeartPy* [@HeartPy], *systole* [@Systole] or *nolds* [@nolds]. The code itself includes a comprehensive test suite to ensure stability and prevent error . Moreover, the issue tracker allows users to easily report any bugs and track their fixation. Thanks to its collaborative and open developpment, as well as its modular organization, *NeuroKit2* is being developped with a longterm perspective in mind, aiming at remaining cutting-edge through its ability to evolve, adapt, and integrate new methods as they are emerging.

<!-- - Powerful and flexible: API -->
Finally, we believe that the design philosophy contributes to a robust  <!--powerful or robust | parentheses at end of sections are not super great; pushing them in the next ?--> yet flexible user interface (API), which is described below. We will then present the most common use-cases, namely event-related and resting state paradigms, through examples and code illustrations. We will conclude by discussing how those examples reveal the way Neurokit plans to address reproducibility issues in research using neurophysiological methods, as well as more foundational and theoretic issues of (neuro)psychology. <!--foundational and theoretic issues : to answer to first statement which is about the growing use of this methods to describe human behavioral, cognitive and affective processes [embodiement, intricacies affectivity and cognition]-->

# Design Philosophy

We cannot stress this enough : *NeuroKit2* aims at being accessible to beginners and, at the same time, offering a maximal level of control to experienced users. Robustness and flexibility of the API are achieved by allowing beginning users to implement complex processing and analyses pipelines with very few functions, while still enabling fine-tuned control and precision to more experienced users. This trade-off is allowed by the implementation of 3 abstract levels of functions.


## Low-level: Signal Processing Base Utilities

The basic building blocks are functions to facilitate general signal processing, i.e., to do filtering, resampling, interpolating, peak detection, etc. These functions are signal-agnostic, and include a lot of tweakable parameters. For instance, one can change the filtering method, frequencies, order etc. Most of these functions are based on validated algorithms present in *scipy* [@scipy]. Examples of such functions include `signal_filter()`, `signal_interpolate()`, `signal_resample()`, `signal_detrend()`. `signal_findpeaks()`.

## Mid-level: Neurophysiological Processing Steps

The signal processing utilities are then used by functions specific to different types of physiological signals. These functions aim at taking care of specific steps of physiological data processing, such as cleaning, peak detection, phase classification or rate computation. Critically, for each type of signals (ECG, RSP, EDA, EMG, etc.), the same function names are called (in the form `signaltype_functiongoal()`) to achieve equivalent goals, such as `*_clean()`, `*_findpeaks()`, `*_process()`, `*_plot()` (replace the star with the signal type, e.g., `ecg_clean()`), making it intuitive and consistent to accross different modalities.

For example, the `rsp_clean()` function uses `signal_filter()` and `signal_detrend()`, with different possible sets of default parameters that can be switched via a "method" argument (corresponding to different published or validated pipelines). For instance, setting `method="khodadad2018"` will use the cleaning workflow described in @khodadad2018optimized. If a user wants to build its own custom cleaning function, he can reproduce the cleaning function but using the low-level signal processing tools with a specific set of parameters.


## High-level Wrappers for Processing and Analysis

Finally, these steps are assembled in front-end "master" functions. For instance, the `ecg_process()` function uses `ecg_clean()`, `ecg_findpeaks()`, `ecg_rate()`. A specific processing pipeline can be selected via the `method` argument of the given function. <!--wait, we should be a bit more specific on *_process() functions--> This `method` is propagated throughout its different subsets in lower-level functions. These modality-specific processing functions allow begginners to compare the outcomes of different pipelines on their data. It facilitates important and time-consuming steps in reproducible research such as validation of data preparation and quality control.

<!--Last but not least ; not sure this expression is quite the tone we're looking for--> The package includes meta-functions (e.g., `bio_process`) that allows the combined processing of multiple types of signals at once. As a result, the existence of these high-level functions allows for reproducible and easy to implement biosignal processing pipelines. Performing all of the steps of physiological preprocessing and processing with sensible defaults, researchers who are not confortable in programming can run their pipeline using one line of code (e.g., `bio_process(ecg=ecg_signal, eda=eda_signal, method='neurokit')`). We find this can be rewarding for begginners that someone without prior expertise in programming can perform cutting-edge feature extractions and visualizations. In fact, for these begginners, it may demistify the usage of "pure programming tools" for their analyses. Importantly however, more advanced users can very easily build their own custom analysis pipeline by using the mid-level functions. Thus, the code structure offers more control over the parameters of pipelines at the cost of learning Python basics. We believe this calibrated trade-off between flexibility and robustness can result into motivating begginners to gradually move away from costly proprietary softwares that refrain reproducible research. And at the same time, one may think that the collaborative environment will also drive them to build their own custom pipeline.





# Example


We will present two examples that illustrate the most common use-cases. The first is an event-related paradigm, in which the interest lies in the momentarily short-term physiological changes related to specific stimuli, while the second shows how to extract the characteristics (features) of the physiological activity during a longer period of time (not necessarily tied to a specific and suddent event).


## Event-related Paradigm

The dataset (available in the package), corresponds to the recording of physiological signals (ECG, EDA, RSP) of one participant presented with four emotional images (from the NAPS database; @marchewka2014nencki), in a typical (albeit highly shortened) experimental psychology paradigm.

The data contains 2.5 minutes of signals recorded at a frequency of 100Hzn and contains three channels correspond to the physiological signals, and one corresponding to the marking of events via a photosensor (which signal decreased when a stimulus was displayed on the screen).


```{python eventrelated_data, include=TRUE, eval=TRUE, echo = TRUE}
# Load the package
import neurokit2 as nk

# Download example dataset
data = nk.data("bio_eventrelated_100hz")

# Visualize 10 seconds of data (on the same scale)
nk.signal_plot(data[900:1900], standardize=True)
```
```{r include=TRUE, eval=TRUE, echo = FALSE, fig.width=10, fig.height=6, fig.cap="Subset of the dataset showing one event (in orange) and the other physiological signals."}
py$data %>%
  standardize() %>%
  mutate(Time = 1:n() / 100) %>%
  slice(900:1900) %>%
  pivot_longer(1:4) %>%
  mutate(name = fct_relevel(name, c("ECG", "RSP", "EDA", "Photosensor"))) %>%
  ggplot(aes(x=Time, y=value, color=name, size=name)) +
  geom_line() +
  theme_modern() +
  scale_color_manual(values=c("ECG"="red", "EDA"="#9C27B0", "RSP"="#2196F3", "Photosensor"="#FF9800")) +
  scale_size_manual(values=c("ECG"=0.66, "EDA"=2, "RSP"=2, "Photosensor"=2)) +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        legend.title = element_blank(),
        legend.position = "top") +
  ylab("Time (s)") +
  guides(size = guide_legend(override.aes = list(size = 2)))
```

```{python eventrelated_analysis, include=TRUE, results="hide", eval=TRUE, echo = TRUE}
# Process the data
df, info = nk.bio_process(ecg=data["ECG"],
                          rsp=data["RSP"],
                          eda=data["EDA"],
                          sampling_rate=100)

# Find events
conditions = ["Negative", "Neutral", "Neutral", "Negative"]
events = nk.events_find(event_channel=data["Photosensor"],
                        threshold_keep='below',
                        event_conditions=conditions)

# Epoch the data
epochs = nk.epochs_create(data=df,
                          events=events,
                          sampling_rate=100,
                          epochs_start=-0.1,
                          epochs_end=4)

# Extract event related features
results = nk.bio_analyze(epochs)

# Show subset of results
results[["Condition", "ECG_Rate_Mean", "RSP_Rate_Mean", "EDA_Peak_Amplitude"]]
```

```{r table1word, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# For word
knitr::kable(py$results[c("Condition", "ECG_Rate_Mean", "RSP_Rate_Mean", "EDA_Peak_Amplitude")], format="markdown", digits = 3, caption = "Subset of the ouput related to event-related analysis characterizing the pattern of physiological changes related to specific stimuli.", row.names = FALSE)
```
```{r table1pdf, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, out.width = "\\textwidth", fig.pos = "!ht", results = "asis"}
# For PDFs
kable(py$results[c("Condition", "ECG_Rate_Mean", "RSP_Rate_Mean", "EDA_Peak_Amplitude")], format="latex", digits = 2, booktabs = TRUE, caption = "Subset of the ouput related to event-related analysis characterizing the pattern of physiological changes related to specific stimuli.", linesep="") %>%
  kableExtra::kable_styling(latex_options = c("hold_position"))
```


The initial dataset has been processed, then segmented to epochs corresponding to windows around each event, and finally relevant features were extracted. These features include the changes in rates of ECG and RSP signals (e.g. maximum, minimum and mean rate after stimulus onset, the time at which they occur), the peak characteristics of EDA signal (e.g., occurrence of skin conductance response - SCR, and if SCR is present, its corresponding peak amplitude, time of peak, rise and recovery time). In addition, for ECG and RSP signals, the information of the respiration and cardiac phases are also extracted (i.e.,  the respiration phase - inspiration/expiration - and cardiac phase - systole/diastole - occuring at the onset of event).

<!--Description is clear, now we need to say how this pipeline facilitates valid interpretations and how it reveals crucial physiological processes that are linked to cognition and affectivity-->


## Resting-state Features

This dataset (also available in the package), corresponds to the recording of physiological signals (ECG, PPG, RSP) during 5 minutes of rest (eyes-closed in a sitted position). The data contains 3 channels recorded at a frequency of 100Hz.

```{python intervalrelated, include=TRUE, results="hide", eval=TRUE, echo = TRUE}
# Load the package
import neurokit2 as nk

# Download example dataset
data = nk.data("bio_resting_5min_100hz")

# Process the data
df, info = nk.bio_process(ecg=data["ECG"],
                          rsp=data["RSP"],
                          sampling_rate=100)

# Extract features
results = nk.bio_analyze(df)

# Show subset of results
results[["ECG_Rate_Mean", "ECG_HRV_RMSSD", "RSP_Rate_Mean", "RSA_P2T_Mean"]]
```

```{r table2word, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# For word
knitr::kable(py$results[c("ECG_Rate_Mean", "ECG_HRV_RMSSD", "RSP_Rate_Mean", "RSA_P2T_Mean")], format="markdown", digits = 3, caption = "Subset of properties characterizing the physiological activity over a period of 5 minutes of resting-state", row.names = FALSE)
```
```{r table2pdf, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, out.width = "\\textwidth", fig.pos = "!ht", results = "asis"}
# For PDFs
kable(py$results[c("ECG_Rate_Mean", "ECG_HRV_RMSSD", "RSP_Rate_Mean", "RSA_P2T_Mean")], format="latex", digits = 2, booktabs = TRUE, caption = "Subset of properties characterizing the physiological activity over a period of 5 minutes of resting-state.", linesep="") %>%
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

The dataset has been processed, and then passed to the analysis function, which extracted properties of physiological activity, such as the rate characteristics of ECG and RSP signals (e.g. the mean and the variability of the heart and breathing rate).

<!--Description is clear, now we need to say how this pipeline facilitates valid interpretations and how it reveals crucial physiological processes that are linked to cognition and affectivity-->


# Conclusion and Future Directions

Despite not having a Graphical User Interface (GUI), *NeuroKit2* is accessible to people with very little knowledge of python or programming in general, thanks to its design choices focusing on user-experience.

Future evolution will mostly be driven by the community and the advances in the field. Possible directions include extending the support for other types of bodily signals (e.g., electrogastrography - EGG, electrooculography - EOG) and strenghtening the efficiency of the code to obtain performance gains for large datasets.

# Conflict of Interest

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

# Acknowledgements

We would like to thank all the contributors (https://neurokit2.readthedocs.io/en/latest/authors.html), and the users for their support.








\newpage

# References
```{r create_r-references}
r_refs(file = "bibliography.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
